{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:15:46.760430Z",
     "start_time": "2019-05-12T22:15:35.125071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from time import gmtime, strftime\n",
    "import random\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import aging as age\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "# Define directory with matlab files\n",
    "# direc = 'D:/MLdata/18-01-09d-Exp/Extract Data/'\n",
    "# direc  = 'D:/Nicholas_ML/18-01-09d-Exp/Extract Data/'\n",
    "direc = 'D:/Nick/MLdata/'\n",
    "# Define directory to save model and plots\n",
    "savedir = 'D:/Nick/MLdata/Model/' + strftime(\"%Y-%m-%d %H-%M\", gmtime()) + '/'\n",
    "\n",
    "random.seed(135)\n",
    "np.random.seed(135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of things are hidden behind the scenes in this code.  This allows for compactness within the Jupyter notebook.\n",
    "\n",
    "In order to properly import the data, there are several options which can be varied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:19:50.007004Z",
     "start_time": "2019-05-12T22:19:49.112294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19-03-15a-Exp', '19-03-19a-Exp', '19-03-26a-Exp']\n"
     ]
    }
   ],
   "source": [
    "# Optimized Data Extractor\n",
    "crop_size = 750\n",
    "split_size = crop_size // 3\n",
    "clip_value = 1\n",
    "image_grid_size = int(crop_size**2 / split_size**2)\n",
    "\n",
    "file_num = 0\n",
    "\n",
    "folders, files = age.seq_file_names(direc = direc, \n",
    "                                which_samples = (1,2,3), \n",
    "                                num_exps = file_num)\n",
    "\n",
    "skip_exp = ['ML_block1_Exp265.mat', \n",
    "            'ML_block1_Exp272.mat',\n",
    "           'ML_block1_Exp278.mat',\n",
    "           'ML_block1_Exp386.mat',\n",
    "           'ML_block1_Exp388.mat',\n",
    "           'ML_block1_Exp392.mat']\n",
    "\n",
    "for skip in skip_exp:\n",
    "    files = list(filter((skip).__ne__, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-12T22:22:15.622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Nick/MLdata/19-03-19a-Exp/Extract Data/ML_block3_Exp348.mat\r"
     ]
    }
   ],
   "source": [
    "length_index, split_images, label_dic = age.data_extractor(files, \n",
    "                     folders, \n",
    "                     direc = direc, \n",
    "                     crop_size = crop_size, \n",
    "                     split_size = split_size,\n",
    "                     clip_value = clip_value,\n",
    "                     subtract = True, \n",
    "                     log_image = True, \n",
    "                     younger = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-12T22:22:33.153Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# age.intensity_plotter(length_index, label_dic, \n",
    "#                       split_images, image_grid_size,\n",
    "#                      normalize_to_1 = True, normalize_all = True, \n",
    "#                       log_plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-12T22:22:33.409Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# age.time_plotter(length_index, files, label_dic, \n",
    "#                  split_images, image_grid_size, full = False)\n",
    "# # age.difference(Fs_label, Fn_label, T_label, split_images, length_index, files, image_grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T22:03:21.109250Z",
     "start_time": "2019-05-12T22:03:20.079607Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data, train_labels, train_meta, test_data, test_labels, test_meta = \\\n",
    "#         age.withhold_sqr(\n",
    "#             split_images = split_images, \n",
    "#             ML_labels = ['T'],\n",
    "#             label_dic = label_dic,\n",
    "#             image_grid_size = image_grid_size, \n",
    "#             log_time = True,\n",
    "#             cols = crop_size//split_size)\n",
    "\n",
    "train_data, train_labels, train_meta, test_data, test_labels, test_meta = \\\n",
    "        age.withold_exp(\n",
    "            split_images = split_images, \n",
    "            ML_labels = ['T'],\n",
    "            label_dic = label_dic,\n",
    "            log_time = True)\n",
    "\n",
    "# train_data, train_labels, test_data, test_labels = \\\n",
    "# age.younger(train_data, train_labels, test_data, test_labels, time_cut = 5)\n",
    "\n",
    "min_val = np.min([np.min(train_data), np.min(test_data)])\n",
    "\n",
    "#Final Renormilization of Images to be between 0 and 1\n",
    "train_data = (train_data - min_val)/(1 - min_val)\n",
    "test_data = (test_data - min_val)/(1 - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T20:33:59.239045Z",
     "start_time": "2019-05-12T20:33:39.157149Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = train_data.shape[1]\n",
    "    \n",
    "# Create the base model\n",
    "# https://keras.io/applications/#inceptionv3\n",
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "                include_top=False, \n",
    "                weights='imagenet', \n",
    "                input_shape=(image_size,image_size,3))\n",
    "\n",
    "base_model.trainable = False\n",
    "    \n",
    "incep_model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.5),\n",
    "    tf.keras.layers.Dropout(rate = 0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.5),\n",
    "    tf.keras.layers.Dropout(rate = 0.3),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.5)\n",
    "    ])\n",
    "\n",
    "#custom_model = tf.keras.Sequential([\n",
    "#        tf.keras.layers.Conv2D(8, kernel_size=(2, 2),\n",
    "#                       input_shape=(image_size, image_size, 1)),\n",
    "#        tf.keras.layers.LeakyReLU(alpha=0.5),\n",
    "#        tf.keras.layers.Dropout(rate = 0.3),\n",
    "#        tf.keras.layers.Conv2D(16, (3, 3)),\n",
    "#        tf.keras.layers.LeakyReLU(alpha=0.5),\n",
    "#        tf.keras.layers.Dropout(rate = 0.3),\n",
    "#        tf.keras.layers.Flatten(),\n",
    "#        tf.keras.layers.Dense(32),\n",
    "#        tf.keras.layers.LeakyReLU(alpha=0.5),\n",
    "#        tf.keras.layers.Dropout(rate = 0.3),\n",
    "#        tf.keras.layers.Dense(1),\n",
    "#        tf.keras.layers.LeakyReLU(alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T20:44:28.327410Z",
     "start_time": "2019-05-12T20:42:10.647710Z"
    }
   },
   "outputs": [],
   "source": [
    "model, history = age.inception_train(\n",
    "                    train_data, \n",
    "                    train_labels, \n",
    "                    test_data, \n",
    "                    test_labels,\n",
    "                    savedir, \n",
    "                    incep_model,\n",
    "                    epochs = 50)\n",
    "\n",
    "# model, history = age.aion(train_data, train_labels, test_data, test_labels,\n",
    "#                     savedir, full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T19:02:05.996850Z",
     "start_time": "2019-05-12T19:01:42.058719Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predic = model.predict(np.tile(\n",
    "    test_data.reshape(test_data.shape[0], \n",
    "    test_data.shape[1], \n",
    "    test_data.shape[2], \n",
    "    1), \n",
    "        3))\n",
    "train_predic = model.predict(np.tile(train_data.reshape(\n",
    "    train_data.shape[0], \n",
    "    train_data.shape[1],  \n",
    "    train_data.shape[2], \n",
    "    1),\n",
    "        3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T19:02:07.689942Z",
     "start_time": "2019-05-12T19:02:05.996850Z"
    }
   },
   "outputs": [],
   "source": [
    "age.hist_plotter(history, savedir + \"Incep_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T19:02:11.079016Z",
     "start_time": "2019-05-12T19:02:07.689942Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_times = train_labels.flatten()\n",
    "train_pred_times = train_predic.flatten()\n",
    "\n",
    "# train_shear = train_labels[:,1]\n",
    "# train_pred_shear = train_predic[:,1]\n",
    "\n",
    "test_times = test_labels.flatten()\n",
    "test_pred_times = test_predic.flatten()\n",
    "\n",
    "# test_shear = test_labels[:,1]\n",
    "# test_pred_shear = test_predic[:,1]\n",
    "\n",
    "age.data_plotter(train_times, train_pred_times, savedir + \"Incep_Age_train\" , 'b')\n",
    "\n",
    "age.data_plotter(test_times, test_pred_times, savedir + \"Incep_Age_test\" , 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
